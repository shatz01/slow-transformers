# ğŸŒ slow-transformers

Our motto: "Go transformers! But dont go too fast. You still have to enjoy life â˜®ï¸"

# Install
```
git clone ...
cd slow-transformers/
pip install -r requirements.txt
```

# Supported Models
- [x] ViT
- [ ] Language Classification Transformer

# Supported Datasets
- [x] cifar

## TODO / Goals list
- Vanilla transformer (or some language tasks)
- fsdp/deepspeed 
- cross attention
- more interesting architechtures (t5, perciever)
- flash attention integration
- jax?
- resnet & hyena for comparison???
- support m1